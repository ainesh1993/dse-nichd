{"cells":[{"cell_type":"markdown","metadata":{"id":"50f5049991824cc68f7205296a9c6c88"},"source":["<a class=\"anchor\" id=\"top\"></a>\n","# Modeling Notebook\n","**Authors: Ainesh Pandey, Demian Gass, Gabriel Gilling**\n","\n","In this notebook, we read in the prepped datasets and start modeling on our selected outcome variables.\n","\n","## Table of Contents\n","\n","[Step 1: Import Required Packages](#step-1) <br>\n","[Step 2: Read and Prepare Datasets](#step-2) <br>\n","[Step 3: Modeling](#step-3) <br>"]},{"cell_type":"markdown","metadata":{"id":"7db401c63c7640cbb129a974a6f6401c"},"source":["<a class=\"anchor\" id=\"step-1\"></a>\n","\n","## Import Required Packages\n","\n","If you do not have the `imbalanced-learn` package installed, run the cell below. If you do have the package already, you can ignore it."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: pandas==1.0.5 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (1.0.5)\n","Requirement already satisfied: pytz>=2017.2 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from pandas==1.0.5) (2021.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from pandas==1.0.5) (2.8.2)\n","Requirement already satisfied: numpy>=1.13.3 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from pandas==1.0.5) (1.19.2)\n","Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.15.0)\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: numpy==1.19.2 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (1.19.2)\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install pandas==1.0.5\n","!pip install numpy==1.19.2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"a335a5e22d0f4768a4179554291d3b88"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install imbalanced-learn -q"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install lightgbm -q"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: sklearn in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (0.0)\n","Requirement already satisfied: scikit-learn in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from sklearn) (1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn->sklearn) (2.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn->sklearn) (1.7.1)\n","Requirement already satisfied: joblib>=0.11 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn->sklearn) (1.0.1)\n","Requirement already satisfied: numpy>=1.14.6 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn->sklearn) (1.19.2)\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["! pip install -U sklearn"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.19.2\n","1.0.5\n"]}],"source":["import sklearn\n","sklearn.__version__\n","\n","import numpy as np\n","print(np.__version__)\n","\n","import pandas as pd\n","print(pd.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: scikit-learn in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (0.24.2)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.0-cp38-cp38-macosx_10_13_x86_64.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: numpy>=1.14.6 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn) (1.21.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn) (2.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages (from scikit-learn) (1.7.1)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.24.2\n","    Uninstalling scikit-learn-0.24.2:\n","      Successfully uninstalled scikit-learn-0.24.2\n","Successfully installed scikit-learn-1.0\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U scikit-learn"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6bc4cd7f-a30a-4863-b7c2-5e8d8cb07e9c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from scipy import stats\n","import pickle\n","\n","from imblearn.under_sampling import NearMiss\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from lightgbm import LGBMClassifier\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import time\n","\n","from my_path import PATH\n"]},{"cell_type":"markdown","metadata":{"id":"041d495c385a466d8fca5ef5f386a432"},"source":["[Back to Top](#top)"]},{"cell_type":"markdown","metadata":{"id":"9c86b505ab2e4d39880129b08c2eca42"},"source":["<a class=\"anchor\" id=\"step-2\"></a>\n","\n","## Read and Prepare Datasets\n","\n","### Input Datasets\n","\n","**Deltas Dataframe**: These are the primary inputs to our model."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5b39779de56c4ddbaec895005de5929c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows: 9289\n","Columns: 209\n"]},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PublicID</th>\n      <th>V1BA01_KG_delta_V2BA01_KG</th>\n      <th>V2BA01_KG_delta_V3BA01_KG</th>\n      <th>V1BA01_LB_delta_V2BA01_LB</th>\n      <th>V2BA01_LB_delta_V3BA01_LB</th>\n      <th>V2BA02b1_delta_V3BA02b1</th>\n      <th>V2BA02a2_delta_V3BA02a2</th>\n      <th>V2BA02a1_delta_V3BA02a1</th>\n      <th>V2BA02b2_delta_V3BA02b2</th>\n      <th>V1CA01_delta_V3CA01</th>\n      <th>...</th>\n      <th>U2BC01_delta_U3BC01</th>\n      <th>U2BB05_delta_U3BB05</th>\n      <th>U2BB04_delta_U3BB04</th>\n      <th>U2BB03_delta_U3BB03</th>\n      <th>U2BB02_delta_U3BB02</th>\n      <th>U2BB01_delta_U3BB01</th>\n      <th>U2BA04_delta_U3BA04</th>\n      <th>U2BA02_DY_delta_U3BA02_DY</th>\n      <th>U2BA02_WK_delta_U3BA02_WK</th>\n      <th>U2BC03e_delta_U3BC03e</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001U</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.512680</td>\n      <td>0.516508</td>\n      <td>0.339237</td>\n      <td>0.5745</td>\n      <td>0.440188</td>\n      <td>0.514788</td>\n      <td>0-1</td>\n      <td>...</td>\n      <td>0-0</td>\n      <td>M-M</td>\n      <td>0.580346</td>\n      <td>0-0</td>\n      <td>0.519531</td>\n      <td>0-0</td>\n      <td>0-0</td>\n      <td>0.502593</td>\n      <td>0.453007</td>\n      <td>S-S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00004O</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.472393</td>\n      <td>0.482693</td>\n      <td>0.336700</td>\n      <td>0.5745</td>\n      <td>0.601595</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2-2</td>\n      <td>2-2</td>\n      <td>0.580346</td>\n      <td>2-2</td>\n      <td>0.541750</td>\n      <td>1-1</td>\n      <td>2-2</td>\n      <td>0.499938</td>\n      <td>0.585123</td>\n      <td>S-S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007I</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.510677</td>\n      <td>0.521473</td>\n      <td>0.395469</td>\n      <td>0.5745</td>\n      <td>0.431082</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2-2</td>\n      <td>2-2</td>\n      <td>0.580346</td>\n      <td>2-2</td>\n      <td>0.513992</td>\n      <td>1-1</td>\n      <td>2-2</td>\n      <td>0.666791</td>\n      <td>0.418275</td>\n      <td>S-S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00008G</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.563604</td>\n      <td>0.554183</td>\n      <td>0.331190</td>\n      <td>0.5745</td>\n      <td>0.447863</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2-2</td>\n      <td>2-2</td>\n      <td>0.580346</td>\n      <td>2-2</td>\n      <td>0.547669</td>\n      <td>1-1</td>\n      <td>2-2</td>\n      <td>0.499814</td>\n      <td>0.519989</td>\n      <td>S-S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00015J</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.530073</td>\n      <td>0.483132</td>\n      <td>0.421487</td>\n      <td>0.5745</td>\n      <td>0.579686</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2-2</td>\n      <td>2-2</td>\n      <td>0.580346</td>\n      <td>2-2</td>\n      <td>0.602954</td>\n      <td>1-1</td>\n      <td>2-2</td>\n      <td>0.583240</td>\n      <td>0.316562</td>\n      <td>S-S</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 209 columns</p>\n</div>","text/plain":"  PublicID  V1BA01_KG_delta_V2BA01_KG  V2BA01_KG_delta_V3BA01_KG  \\\n0   00001U                   0.522239                   0.663086   \n1   00004O                   0.522239                   0.663086   \n2   00007I                   0.522239                   0.663086   \n3   00008G                   0.522239                   0.663086   \n4   00015J                   0.522239                   0.663086   \n\n   V1BA01_LB_delta_V2BA01_LB  V2BA01_LB_delta_V3BA01_LB  \\\n0                   0.512680                   0.516508   \n1                   0.472393                   0.482693   \n2                   0.510677                   0.521473   \n3                   0.563604                   0.554183   \n4                   0.530073                   0.483132   \n\n   V2BA02b1_delta_V3BA02b1  V2BA02a2_delta_V3BA02a2  V2BA02a1_delta_V3BA02a1  \\\n0                 0.339237                   0.5745                 0.440188   \n1                 0.336700                   0.5745                 0.601595   \n2                 0.395469                   0.5745                 0.431082   \n3                 0.331190                   0.5745                 0.447863   \n4                 0.421487                   0.5745                 0.579686   \n\n   V2BA02b2_delta_V3BA02b2 V1CA01_delta_V3CA01  ... U2BC01_delta_U3BC01  \\\n0                 0.514788                 0-1  ...                 0-0   \n1                 0.514788                 1-1  ...                 2-2   \n2                 0.514788                 1-1  ...                 2-2   \n3                 0.514788                 1-1  ...                 2-2   \n4                 0.514788                 1-1  ...                 2-2   \n\n  U2BB05_delta_U3BB05 U2BB04_delta_U3BB04 U2BB03_delta_U3BB03  \\\n0                 M-M            0.580346                 0-0   \n1                 2-2            0.580346                 2-2   \n2                 2-2            0.580346                 2-2   \n3                 2-2            0.580346                 2-2   \n4                 2-2            0.580346                 2-2   \n\n  U2BB02_delta_U3BB02 U2BB01_delta_U3BB01 U2BA04_delta_U3BA04  \\\n0            0.519531                 0-0                 0-0   \n1            0.541750                 1-1                 2-2   \n2            0.513992                 1-1                 2-2   \n3            0.547669                 1-1                 2-2   \n4            0.602954                 1-1                 2-2   \n\n  U2BA02_DY_delta_U3BA02_DY U2BA02_WK_delta_U3BA02_WK  U2BC03e_delta_U3BC03e  \n0                  0.502593                  0.453007                    S-S  \n1                  0.499938                  0.585123                    S-S  \n2                  0.666791                  0.418275                    S-S  \n3                  0.499814                  0.519989                    S-S  \n4                  0.583240                  0.316562                    S-S  \n\n[5 rows x 209 columns]"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df_deltas = pd.read_csv(\"delta_df.csv\")\n","\n","# Normalize numeric features in deltas dataframe\n","for column in df_deltas.columns:\n","    if df_deltas[column].dtype == 'float64':\n","        df_deltas[column] = (df_deltas[column] - df_deltas[column].min()) / (df_deltas[column].max() - df_deltas[column].min())\n","\n","print('Rows:',    df_deltas.shape[0])\n","print('Columns:', df_deltas.shape[1])\n","df_deltas.head()"]},{"cell_type":"markdown","metadata":{"id":"c258045bdd004bddbde7507fe30a6544"},"source":["**Covariates Dataframe**: We will adjust our models for selected demographic and socio-economic variables."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"486bd5d38a1b43c587d003f7ab72aff1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows: 9289\n","Columns: 17\n"]},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GAwks_screen</th>\n      <th>Age_at_V1</th>\n      <th>eRace</th>\n      <th>BMI</th>\n      <th>Education</th>\n      <th>GravCat</th>\n      <th>SmokeCat1</th>\n      <th>SmokeCat2</th>\n      <th>Ins_Govt</th>\n      <th>Ins_Mil</th>\n      <th>Ins_Comm</th>\n      <th>Ins_Pers</th>\n      <th>Ins_Othr</th>\n      <th>V1AF14</th>\n      <th>V1AG01</th>\n      <th>V1AG11</th>\n      <th>PublicID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.750</td>\n      <td>0.50000</td>\n      <td>7</td>\n      <td>0.265029</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>00001U</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.750</td>\n      <td>0.25000</td>\n      <td>6</td>\n      <td>0.180132</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>00004O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.625</td>\n      <td>0.18750</td>\n      <td>5</td>\n      <td>0.147336</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00007I</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.625</td>\n      <td>0.53125</td>\n      <td>5</td>\n      <td>0.239248</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>00008G</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.750</td>\n      <td>0.59375</td>\n      <td>5</td>\n      <td>0.114749</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>2</td>\n      <td>00015J</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   GAwks_screen  Age_at_V1 eRace       BMI Education GravCat SmokeCat1  \\\n0         0.750    0.50000     7  0.265029       6.0     1.0       1.0   \n1         0.750    0.25000     6  0.180132       3.0     1.0       2.0   \n2         0.625    0.18750     5  0.147336       3.0     3.0       1.0   \n3         0.625    0.53125     5  0.239248       2.0     1.0       2.0   \n4         0.750    0.59375     5  0.114749       6.0     1.0       2.0   \n\n  SmokeCat2 Ins_Govt Ins_Mil Ins_Comm Ins_Pers Ins_Othr V1AF14 V1AG01 V1AG11  \\\n0       2.0      2.0     2.0      1.0      2.0      2.0     11      1      2   \n1       2.0      2.0     2.0      1.0      2.0      2.0      5      2      2   \n2       1.0      1.0     2.0      2.0      2.0      2.0      4      1      1   \n3       2.0      2.0     2.0      1.0      1.0      2.0     10      1      2   \n4       2.0      2.0     2.0      1.0      2.0      2.0     12      1      2   \n\n  PublicID  \n0   00001U  \n1   00004O  \n2   00007I  \n3   00008G  \n4   00015J  "},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["with open('df_covariates.pkl', 'rb') as f:\n","    df_covariates = pickle.load(f)\n","    \n","# Normalize numeric features in covariates dataframe\n","for column in df_covariates.columns:\n","    if df_covariates[column].dtype == 'float64':\n","        df_covariates[column] = (df_covariates[column] - df_covariates[column].min()) / (df_covariates[column].max() - df_covariates[column].min())\n","\n","print('Rows:',    df_covariates.shape[0])\n","print('Columns:', df_covariates.shape[1])\n","df_covariates.head()"]},{"cell_type":"markdown","metadata":{"id":"5b9aa052-54a4-4e51-bd00-a86171c0971e"},"source":["**Base Dataframe**: Combine the inputs (the deltas and the covariates) into the base dataset."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"c2d60f1cb6584d619a5f0fdcaf311764"},"outputs":[{"data":{"text/plain":"(9289, 225)"},"metadata":{},"output_type":"display_data"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PublicID</th>\n      <th>V1BA01_KG_delta_V2BA01_KG</th>\n      <th>V2BA01_KG_delta_V3BA01_KG</th>\n      <th>V1BA01_LB_delta_V2BA01_LB</th>\n      <th>V2BA01_LB_delta_V3BA01_LB</th>\n      <th>V2BA02b1_delta_V3BA02b1</th>\n      <th>V2BA02a2_delta_V3BA02a2</th>\n      <th>V2BA02a1_delta_V3BA02a1</th>\n      <th>V2BA02b2_delta_V3BA02b2</th>\n      <th>V1CA01_delta_V3CA01</th>\n      <th>...</th>\n      <th>SmokeCat1</th>\n      <th>SmokeCat2</th>\n      <th>Ins_Govt</th>\n      <th>Ins_Mil</th>\n      <th>Ins_Comm</th>\n      <th>Ins_Pers</th>\n      <th>Ins_Othr</th>\n      <th>V1AF14</th>\n      <th>V1AG01</th>\n      <th>V1AG11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001U</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.512680</td>\n      <td>0.516508</td>\n      <td>0.339237</td>\n      <td>0.5745</td>\n      <td>0.440188</td>\n      <td>0.514788</td>\n      <td>0-1</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00004O</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.472393</td>\n      <td>0.482693</td>\n      <td>0.336700</td>\n      <td>0.5745</td>\n      <td>0.601595</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007I</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.510677</td>\n      <td>0.521473</td>\n      <td>0.395469</td>\n      <td>0.5745</td>\n      <td>0.431082</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00008G</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.563604</td>\n      <td>0.554183</td>\n      <td>0.331190</td>\n      <td>0.5745</td>\n      <td>0.447863</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00015J</td>\n      <td>0.522239</td>\n      <td>0.663086</td>\n      <td>0.530073</td>\n      <td>0.483132</td>\n      <td>0.421487</td>\n      <td>0.5745</td>\n      <td>0.579686</td>\n      <td>0.514788</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 225 columns</p>\n</div>","text/plain":"  PublicID  V1BA01_KG_delta_V2BA01_KG  V2BA01_KG_delta_V3BA01_KG  \\\n0   00001U                   0.522239                   0.663086   \n1   00004O                   0.522239                   0.663086   \n2   00007I                   0.522239                   0.663086   \n3   00008G                   0.522239                   0.663086   \n4   00015J                   0.522239                   0.663086   \n\n   V1BA01_LB_delta_V2BA01_LB  V2BA01_LB_delta_V3BA01_LB  \\\n0                   0.512680                   0.516508   \n1                   0.472393                   0.482693   \n2                   0.510677                   0.521473   \n3                   0.563604                   0.554183   \n4                   0.530073                   0.483132   \n\n   V2BA02b1_delta_V3BA02b1  V2BA02a2_delta_V3BA02a2  V2BA02a1_delta_V3BA02a1  \\\n0                 0.339237                   0.5745                 0.440188   \n1                 0.336700                   0.5745                 0.601595   \n2                 0.395469                   0.5745                 0.431082   \n3                 0.331190                   0.5745                 0.447863   \n4                 0.421487                   0.5745                 0.579686   \n\n   V2BA02b2_delta_V3BA02b2 V1CA01_delta_V3CA01  ... SmokeCat1 SmokeCat2  \\\n0                 0.514788                 0-1  ...       1.0       2.0   \n1                 0.514788                 1-1  ...       2.0       2.0   \n2                 0.514788                 1-1  ...       1.0       1.0   \n3                 0.514788                 1-1  ...       2.0       2.0   \n4                 0.514788                 1-1  ...       2.0       2.0   \n\n  Ins_Govt Ins_Mil Ins_Comm Ins_Pers Ins_Othr V1AF14 V1AG01  V1AG11  \n0      2.0     2.0      1.0      2.0      2.0     11      1       2  \n1      2.0     2.0      1.0      2.0      2.0      5      2       2  \n2      1.0     2.0      2.0      2.0      2.0      4      1       1  \n3      2.0     2.0      1.0      1.0      2.0     10      1       2  \n4      2.0     2.0      1.0      2.0      2.0     12      1       2  \n\n[5 rows x 225 columns]"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_base = df_deltas.merge(df_covariates, on='PublicID', how='inner')\n","\n","display(df_base.shape)\n","df_base.head()"]},{"cell_type":"markdown","metadata":{"id":"f512005037724e0c97d54d2789c06429"},"source":["### Targets Datasets\n","\n","**Target Dataframe**: The target variables we will be predicting on."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"f15f473bd49a48248684658c9a510b21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows: 9289\n","Columns: 19\n"]},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PEgHTN</th>\n      <th>ChronHTN</th>\n      <th>CMAD01a</th>\n      <th>CMAD01b</th>\n      <th>CMAD01c</th>\n      <th>CMAD01d</th>\n      <th>CMAD01e</th>\n      <th>CMAD01f</th>\n      <th>CMAD01g</th>\n      <th>CMAD01h</th>\n      <th>CMAE04a1c</th>\n      <th>CMAE04a2c</th>\n      <th>CMAE04a3c</th>\n      <th>CMAE04a4c</th>\n      <th>CMAE04a5c</th>\n      <th>Stillbirth</th>\n      <th>Miscarriage</th>\n      <th>Termination</th>\n      <th>PublicID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00001U</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>00004O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>00007I</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>00008G</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>00015J</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   PEgHTN  ChronHTN  CMAD01a  CMAD01b  CMAD01c  CMAD01d  CMAD01e  CMAD01f  \\\n0     NaN       NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n1     0.0       0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n2     0.0       0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n3     0.0       0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n4     0.0       0.0      NaN      NaN      NaN      NaN      NaN      NaN   \n\n   CMAD01g  CMAD01h  CMAE04a1c  CMAE04a2c  CMAE04a3c  CMAE04a4c  CMAE04a5c  \\\n0      NaN      NaN        NaN        NaN        NaN        NaN        NaN   \n1      NaN      NaN        0.0        0.0        0.0        0.0        0.0   \n2      NaN      NaN        0.0        0.0        0.0        0.0        0.0   \n3      NaN      NaN        0.0        0.0        0.0        0.0        0.0   \n4      NaN      NaN        0.0        0.0        0.0        0.0        0.0   \n\n   Stillbirth  Miscarriage  Termination PublicID  \n0         NaN          NaN          NaN   00001U  \n1         0.0          0.0          0.0   00004O  \n2         0.0          0.0          0.0   00007I  \n3         0.0          0.0          0.0   00008G  \n4         0.0          0.0          0.0   00015J  "},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["with open('targets_df.pkl', 'rb') as f:\n","    df_targets = pickle.load(f)\n","\n","print('Rows:',    df_targets.shape[0])\n","print('Columns:', df_targets.shape[1])\n","df_targets.head()"]},{"cell_type":"markdown","metadata":{"id":"7e72f318dfb94de482eff6e03f58d488"},"source":["### Auxiliary Datasets\n","\n","#### Variables Dictionary"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"a8c89a3e519b460e920bbb9e33193fe4"},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variable Name</th>\n      <th>Variable Label</th>\n      <th>Variable Type</th>\n      <th>Variable Code List</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PublicID</td>\n      <td>Public nuMoM2b ID</td>\n      <td>Character</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A02_Complete</td>\n      <td>(A02) Data entry status</td>\n      <td>Character</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A02_Complete_1</td>\n      <td>(A02) Data entry status</td>\n      <td>Character</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A02_Status</td>\n      <td>(A02) Validation status</td>\n      <td>Character</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A02_Status_1</td>\n      <td>(A02) Validation status</td>\n      <td>Character</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    Variable Name           Variable Label Variable Type Variable Code List\n0        PublicID        Public nuMoM2b ID     Character                NaN\n1    A02_Complete  (A02) Data entry status     Character                NaN\n2  A02_Complete_1  (A02) Data entry status     Character                NaN\n3      A02_Status  (A02) Validation status     Character                NaN\n4    A02_Status_1  (A02) Validation status     Character                NaN"},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["variables_df = pd.read_excel(PATH+'/nuMoM2b_Codebook_NICHD Data Challenge.xlsx',\n","                              sheet_name='nuMoM2b_Variables',\n","                              header=1,\n","                              usecols=['Variable Name', 'Variable Label', 'Variable Type', 'Variable Code List\\n(if Coded)'],\n","                              engine='openpyxl')\n","variables_df.columns = ['Variable Name', 'Variable Label', 'Variable Type', 'Variable Code List']\n","\n","variables_df.head()"]},{"cell_type":"markdown","metadata":{"id":"83c02c536a7246cb88e42b2dadb0c6e6"},"source":["### Results Dictionaries\n","\n","**Features Importance Dictionary**: We will store the feature importances for each target variable in this dictionary."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"0516589954e14279882f47dd12dd857f"},"outputs":[],"source":["feature_results_dict = {}"]},{"cell_type":"markdown","metadata":{"id":"b657109324a44245826216dbefaa2e84"},"source":["**Model Results Dictionary**: We will store the model results for each target variables in this dictionary."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"3e62ecc3acf34b6f9b4a569ed39e0c82"},"outputs":[],"source":["model_results_dict = {}"]},{"cell_type":"markdown","metadata":{"id":"61d1ca9b0a374ab38b520ef3d197f656"},"source":["[Back to Top](#top)"]},{"cell_type":"markdown","metadata":{"id":"0d9fcb42172c46d08f188a1889663fdf"},"source":["<a class=\"anchor\" id=\"step-3\"></a>\n","\n","## Modeling\n","\n","We will try the following modeling approaches.\n","- `Logistic Regression`: EXPLANATION FOR CHOICE\n","- `Random Forest`: EXPLANATION FOR CHOICE\n","- `Light Gradient-Boosted Model`: EXPLANATION FOR CHOICE"]},{"cell_type":"markdown","metadata":{"id":"9508afee-c3d2-4622-a2f5-fcaddd392896"},"source":["### Helper Functions\n","\n","These will be used in the master function."]},{"cell_type":"code","execution_count":57,"metadata":{"id":"99d7f97dcc1049ad8f9987147988269f"},"outputs":[],"source":["# The master function will use this helper function to prep the data for each target variable\n","def prep_and_split_data(target, df_base, df_targets):\n","    \n","    try:\n","        # append target feature to base dataframe\n","        df = df_base.merge(df_targets[['PublicID', target]], on='PublicID').drop('PublicID', axis=1)\n","\n","        # drop rows missing the output feature\n","        # print('  Num rows before dropping:', df.shape[0])\n","        # print('  Num missing values:', df[target].isna().sum())\n","        df = df.dropna(subset=[target])\n","        # print('  Num rows after dropping:', df.shape[0])\n","\n","        # split into X and y\n","        X = df.drop([target], axis = 1)\n","        y = df[target].astype(int)\n","\n","        # drop correlated features\n","        # print('  Num columns before dropping correlated features:', X.shape[1])\n","        corr = X.corr()\n","        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n","        to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n","        X.drop(to_drop, axis=1, inplace=True)\n","        # print('  Num columns after dropping correlated features:', X.shape[1])\n","\n","        # one-hot encode X\n","        X_dummied = pd.get_dummies(X, prefix_sep='__')\n","        # print('  Num columns after one-hot encoding:', X_dummied.shape[1])\n","        \n","        # train/test split with NearMiss undersampling\n","        X_dummied, y = NearMiss(version=3, n_neighbors_ver3=3).fit_resample(X_dummied, y)\n","        # print('  Num rows after Near-Miss undersampling:', X_dummied.shape[0])\n","        print('  Dataframe shape after cleaning:', str(X_dummied.shape))\n","\n","        # save dataframe for access during analysis phase\n","        filename = 'df_' + target + '.pkl'\n","        with open(filename, 'wb') as f:\n","            pickle.dump(pd.concat([X_dummied, y], axis=1), f)\n","        # print('  Dataframe saved:', filename)\n","\n","        return train_test_split(X_dummied, y, test_size=0.3, random_state=42, stratify = y)\n","    \n","    except Exception as e:\n","        print(e)\n","    \n","#     # if too many rows for modeling, reduce\n","#     if X_dummied.shape[0] > 1000:\n","#         print('  Num rows after further undersampling: 1000')\n","#         print()\n","#         return train_test_split(X_dummied, y, train_size=700, test_size=300, random_state=42, stratify = y)\n","#     else:\n","#         print()\n","#         return train_test_split(X_dummied, y, test_size=0.3, random_state=42, stratify = y)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"e5b667adfbdf478a8a05c918400e3626"},"outputs":[],"source":["# The master function will use this function to initialize the feature_results dataframe for each target variable\n","def initialize_feature_results(X_dummied):\n","    \n","    # initialize the feature results dataframe\n","    feature_results = pd.DataFrame(columns=['Feature', 'Variable1 Name', 'Variable1 Desc', 'Variable2 Name', 'Variable2 Desc',\n","                                            'LogR_FeatureImportance', 'RanF_FeatureImportance', 'LGBM_FeatureImportance'])\n","    \n","    # populate the \"Feature\" column\n","    feature_results['Feature'] = X_dummied.columns\n","\n","    # extract the individual features from the delta columns, nan for second feature if not a delta column\n","    feature_split = [x.split('__')[0].split('_delta_') for x in feature_results['Feature']]\n","    for x in feature_split:\n","        if(len(x) == 1): x.append(np.nan)\n","    feature_results['Variable1 Name'] = [x[0] for x in feature_split]\n","    feature_results['Variable2 Name'] = [x[1] for x in feature_split]\n","\n","    # extract the feature labels for all features\n","    feature_results['Variable1 Desc'] = feature_results[['Variable1 Name']].merge(variables_df[['Variable Name', 'Variable Label']], how='left',\n","                                                                                  left_on='Variable1 Name', right_on='Variable Name')['Variable Label']\n","    feature_results['Variable2 Desc'] = feature_results[['Variable2 Name']].merge(variables_df[['Variable Name', 'Variable Label']], how='left',\n","                                                                                  left_on='Variable2 Name', right_on='Variable Name')['Variable Label']\n","\n","    # extract the feature labels for all features\n","    feature_results['Variable1 Desc'] = feature_results[['Variable1 Name']].merge(variables_df[['Variable Name', 'Variable Label']], how='left',\n","                                                                                  left_on='Variable1 Name', right_on='Variable Name')['Variable Label']\n","    feature_results['Variable2 Desc'] = feature_results[['Variable2 Name']].merge(variables_df[['Variable Name', 'Variable Label']], how='left',\n","                                                                                  left_on='Variable2 Name', right_on='Variable Name')['Variable Label']\n","    \n","    return feature_results"]},{"cell_type":"markdown","metadata":{"id":"fa55cf83739049d6a26b5e8e92c2099c"},"source":["### Functions for Modeling Approaches\n","\n","***\n","**Logistic Regression**\n","***"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  Dataframe shape after cleaning: (168, 2001)\n"]}],"source":["X_train, X_test, y_train, y_test = prep_and_split_data(target, df_base, df_targets)\n","\n","# initialize model results dictionary and feature results dataframe for selected target variable\n","model_results = {}\n","feature_results = initialize_feature_results(X_train)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Variable1 Name</th>\n      <th>Variable1 Desc</th>\n      <th>Variable2 Name</th>\n      <th>Variable2 Desc</th>\n      <th>LogR_FeatureImportance</th>\n      <th>RanF_FeatureImportance</th>\n      <th>LGBM_FeatureImportance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1BA01_KG_delta_V2BA01_KG</td>\n      <td>V1BA01_KG</td>\n      <td>(V1B) Weight - kg</td>\n      <td>V2BA01_KG</td>\n      <td>(V2B) Weight - kg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V2BA01_KG_delta_V3BA01_KG</td>\n      <td>V2BA01_KG</td>\n      <td>(V2B) Weight - kg</td>\n      <td>V3BA01_KG</td>\n      <td>(V3B) Weight - kg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1BA01_LB_delta_V2BA01_LB</td>\n      <td>V1BA01_LB</td>\n      <td>(V1B) Weight - lbs</td>\n      <td>V2BA01_LB</td>\n      <td>(V2B) Weight - lbs</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V2BA01_LB_delta_V3BA01_LB</td>\n      <td>V2BA01_LB</td>\n      <td>(V2B) Weight - lbs</td>\n      <td>V3BA01_LB</td>\n      <td>(V3B) Weight - lbs</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V2BA02b1_delta_V3BA02b1</td>\n      <td>V2BA02b1</td>\n      <td>(V2B) Resting blood pressure - Diastolic measu...</td>\n      <td>V3BA02b1</td>\n      <td>(V3B) Resting blood pressure - Diastolic measu...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>V1AG01__2.0</td>\n      <td>V1AG01</td>\n      <td>(V1A) Have you ever drunk alcohol?</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>V1AG11__1</td>\n      <td>V1AG11</td>\n      <td>(V1A) Have you ever used illegal drugs or drug...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>V1AG11__1.0</td>\n      <td>V1AG11</td>\n      <td>(V1A) Have you ever used illegal drugs or drug...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>V1AG11__2</td>\n      <td>V1AG11</td>\n      <td>(V1A) Have you ever used illegal drugs or drug...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2000</th>\n      <td>V1AG11__2.0</td>\n      <td>V1AG11</td>\n      <td>(V1A) Have you ever used illegal drugs or drug...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2001 rows × 8 columns</p>\n</div>","text/plain":"                        Feature Variable1 Name  \\\n0     V1BA01_KG_delta_V2BA01_KG      V1BA01_KG   \n1     V2BA01_KG_delta_V3BA01_KG      V2BA01_KG   \n2     V1BA01_LB_delta_V2BA01_LB      V1BA01_LB   \n3     V2BA01_LB_delta_V3BA01_LB      V2BA01_LB   \n4       V2BA02b1_delta_V3BA02b1       V2BA02b1   \n...                         ...            ...   \n1996                V1AG01__2.0         V1AG01   \n1997                  V1AG11__1         V1AG11   \n1998                V1AG11__1.0         V1AG11   \n1999                  V1AG11__2         V1AG11   \n2000                V1AG11__2.0         V1AG11   \n\n                                         Variable1 Desc Variable2 Name  \\\n0                                     (V1B) Weight - kg      V2BA01_KG   \n1                                     (V2B) Weight - kg      V3BA01_KG   \n2                                    (V1B) Weight - lbs      V2BA01_LB   \n3                                    (V2B) Weight - lbs      V3BA01_LB   \n4     (V2B) Resting blood pressure - Diastolic measu...       V3BA02b1   \n...                                                 ...            ...   \n1996                 (V1A) Have you ever drunk alcohol?            NaN   \n1997  (V1A) Have you ever used illegal drugs or drug...            NaN   \n1998  (V1A) Have you ever used illegal drugs or drug...            NaN   \n1999  (V1A) Have you ever used illegal drugs or drug...            NaN   \n2000  (V1A) Have you ever used illegal drugs or drug...            NaN   \n\n                                         Variable2 Desc  \\\n0                                     (V2B) Weight - kg   \n1                                     (V3B) Weight - kg   \n2                                    (V2B) Weight - lbs   \n3                                    (V3B) Weight - lbs   \n4     (V3B) Resting blood pressure - Diastolic measu...   \n...                                                 ...   \n1996                                                NaN   \n1997                                                NaN   \n1998                                                NaN   \n1999                                                NaN   \n2000                                                NaN   \n\n     LogR_FeatureImportance RanF_FeatureImportance LGBM_FeatureImportance  \n0                       NaN                    NaN                    NaN  \n1                       NaN                    NaN                    NaN  \n2                       NaN                    NaN                    NaN  \n3                       NaN                    NaN                    NaN  \n4                       NaN                    NaN                    NaN  \n...                     ...                    ...                    ...  \n1996                    NaN                    NaN                    NaN  \n1997                    NaN                    NaN                    NaN  \n1998                    NaN                    NaN                    NaN  \n1999                    NaN                    NaN                    NaN  \n2000                    NaN                    NaN                    NaN  \n\n[2001 rows x 8 columns]"},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["model_results = {}\n","feature_results = initialize_feature_results(X_train)\n","feature_results"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"]}],"source":["param_grid = { 'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 10.0] }\n","    \n","    # run the cross-validated grid search to identify the best parameters for the model\n","from sklearn.linear_model import LogisticRegression\n","CV_clf = GridSearchCV(estimator=LogisticRegression(penalty='l1', solver='liblinear', random_state=42), \n","                        scoring='f1',\n","                          param_grid=param_grid, n_jobs=-1, verbose=1).fit(X_train, y_train)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"01b5b5ae108e42c3a133f0d1fad76654"},"outputs":[],"source":["# create function that runs and tunes logistic regression, outputs results\n","def model_logisticregression_tuned(X_train, y_train, X_test, y_test):\n","    \n","    # create parameter grid to fine-tune model\n","    param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 10.0] }\n","    \n","    # run the cross-validated grid search to identify the best parameters for the model\n","    CV_clf = GridSearchCV(estimator=LogisticRegression(penalty='l1', solver='liblinear', random_state=42), scoring='f1',\n","                          param_grid=param_grid, n_jobs=-1, verbose=0).fit(X_train, y_train)\n","    \n","    # extract the best parameters, as selected by the grid search\n","    best_params = CV_clf.best_params_\n","    best_C = best_params['C']\n","    \n","    # create the final RandomForestClassifier\n","    best_clf = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, C = best_C).fit(X_train, y_train)\n","    \n","    # predict on the test set\n","    y_pred = (np.round(best_clf.predict(X_test)))\n","\n","    # print(y_test)\n","    # print(y_pred)\n","    \n","    # Create dataframe for parameters and feature importances\n","    features_df = pd.DataFrame()\n","    features_df['Parameter'] = X_train.columns.to_list()\n","    features_df['Feature Importance'] = best_clf.coef_[0]\n","    \n","    # return the features dataframe and a classification report\n","    return [features_df, classification_report(y_test, y_pred, output_dict = True)]"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"e165cefe6a5144e3823392f3c8cd9dbc"},"outputs":[],"source":["# create function that runs and tunes random forest, outputs results\n","def model_randomforest_tuned(X_train, y_train, X_test, y_test):\n","    \n","    # create parameter grid to fine-tune model\n","    param_grid = { \n","        'n_estimators': range(100, 600, 100),\n","        'max_features': ['auto', 'log2', 0.2, 0.25, 0.33, 0.5],\n","        'max_depth' : [None, 4, 6, 8],\n","        'criterion' : ['gini', 'entropy']\n","    }\n","    \n","    # run the cross-validated grid search to identify the best parameters for the model\n","    CV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), scoring='f1',\n","                          param_grid=param_grid, n_jobs=-1, verbose=0).fit(X_train, y_train)\n","    \n","    # extract the best parameters, as selected by the grid search\n","    best_params = CV_rfc.best_params_\n","    best_n_estimators = best_params['n_estimators']\n","    best_max_features = best_params['max_features']\n","    best_max_depth = best_params['max_depth']\n","    best_criterion = best_params['criterion']\n","    \n","    # create the final RandomForestClassifier\n","    best_rfc = RandomForestClassifier(random_state=42,\n","                                      max_features=best_max_features,\n","                                      n_estimators=best_n_estimators,\n","                                      max_depth=best_max_depth,\n","                                      criterion=best_criterion).fit(X_train, y_train)\n","    \n","    # predict on the test set\n","    y_pred = best_rfc.predict(X_test)\n","    \n","    # Create dataframe for parameters and feature importances\n","    features_df = pd.DataFrame()\n","    features_df['Parameter'] = X_train.columns.to_list()\n","    features_df['Feature Importance'] = best_rfc.feature_importances_\n","    \n","    # return the features dataframe and a classification report\n","    return [features_df, classification_report(y_test, y_pred, output_dict = True)]"]},{"cell_type":"markdown","metadata":{"id":"b6e22ae093ea462b8d612d0a114f725e"},"source":["***\n","**Light GBM**\n","***"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"0bc0c084806d4ef78956fc264b4410b5"},"outputs":[],"source":["# create function that runs lgbm, outputs results\n","def model_lgbm_tuned(X_train, y_train, X_test, y_test):\n","    \n","    # create parameter grid to fine-tune model\n","    param_grid = {\n","        'colsample_bytree': [0.8, 1.0],\n","        'max_depth': [15, 20, -1],\n","        'num_leaves': [10, 20, 31],\n","        'reg_alpha': [0, 0.5, 1.0],\n","        'reg_lambda': [0, 0.5, 1.0],\n","        'min_split_gain': [0, 0.2, 0.4],\n","        'subsample': [0.8, 1.0]\n","    }\n","    \n","    # run the cross-validated grid search to identify the best parameters for the model\n","    CV_lgb = GridSearchCV(estimator=LGBMClassifier(random_state=42), scoring='f1',\n","                          param_grid=param_grid, n_jobs=-1, verbose=0).fit(X_train, y_train)\n","    \n","    # extract the best parameters, as selected by the grid search\n","    best_params = CV_lgb.best_params_\n","    best_colsample_bytree = best_params['colsample_bytree']\n","    best_max_depth = best_params['max_depth']\n","    best_num_leaves = best_params['num_leaves']\n","    best_reg_alpha = best_params['reg_alpha']\n","    best_reg_lambda = best_params['reg_lambda']\n","    best_min_split_gain = best_params['min_split_gain']\n","    best_subsample = best_params['subsample']\n","    \n","    # create the final LGBMClassifier\n","    best_lgb = LGBMClassifier(random_state=42,\n","                              colsample_bytree=best_colsample_bytree,\n","                              max_depth=best_max_depth,\n","                              num_leaves=best_num_leaves,\n","                              reg_alpha=best_reg_alpha,\n","                              reg_lambda=best_reg_lambda,\n","                              min_split_gain=best_min_split_gain,\n","                              subsample=best_subsample).fit(X_train, y_train)\n","    \n","    # predict on the test set\n","    y_pred = best_lgb.predict(X_test)\n","\n","    # create dataframe for parameters and feature importances\n","    features_df = pd.DataFrame()\n","    features_df['Parameter'] = best_lgb.feature_name_\n","    features_df['Feature Importance'] = best_lgb.feature_importances_\n","\n","    # return the features dataframe and a classification report\n","    return [features_df, classification_report(y_test, y_pred, output_dict = True)]"]},{"cell_type":"markdown","metadata":{"id":"325fafcabd9e4a028fcfb5a300494c6b"},"source":["### Master Modeling Function"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"text/plain":"[                      Parameter  Feature Importance\n 0     V1BA01_KG_delta_V2BA01_KG            0.000000\n 1     V2BA01_KG_delta_V3BA01_KG            0.000000\n 2     V1BA01_LB_delta_V2BA01_LB            0.000000\n 3     V2BA01_LB_delta_V3BA01_LB            0.000000\n 4       V2BA02b1_delta_V3BA02b1            0.000000\n ...                         ...                 ...\n 1996                V1AG01__2.0            0.000000\n 1997                  V1AG11__1            0.000000\n 1998                V1AG11__1.0            0.000000\n 1999                  V1AG11__2           -0.221689\n 2000                V1AG11__2.0            0.000000\n \n [2001 rows x 2 columns],\n {'0': {'precision': 0.5,\n   'recall': 0.34615384615384615,\n   'f1-score': 0.40909090909090906,\n   'support': 26},\n  '1': {'precision': 0.48484848484848486,\n   'recall': 0.64,\n   'f1-score': 0.5517241379310344,\n   'support': 25},\n  'accuracy': 0.49019607843137253,\n  'macro avg': {'precision': 0.49242424242424243,\n   'recall': 0.4930769230769231,\n   'f1-score': 0.4804075235109717,\n   'support': 51},\n  'weighted avg': {'precision': 0.49257278669043375,\n   'recall': 0.49019607843137253,\n   'f1-score': 0.47900915852234305,\n   'support': 51}}]"},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["model_logisticregression_tuned(X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  Training and tuning Logistic Regression model...\n","166    1\n","124    1\n","59     0\n","37     0\n","88     1\n","60     0\n","63     0\n","160    1\n","51     0\n","118    1\n","71     0\n","79     0\n","2      0\n","95     1\n","77     0\n","14     0\n","154    1\n","161    1\n","84     1\n","158    1\n","94     1\n","128    1\n","23     0\n","143    1\n","80     0\n","117    1\n","1      0\n","26     0\n","92     1\n","48     0\n","90     1\n","152    1\n","91     1\n","155    1\n","112    1\n","20     0\n","72     0\n","148    1\n","21     0\n","24     0\n","57     0\n","32     0\n","78     0\n","74     0\n","29     0\n","98     1\n","43     0\n","111    1\n","116    1\n","146    1\n","52     0\n","Name: CMAD01a, dtype: int64\n","[0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1\n"," 1 0 1 1 0 1 1 0 0 0 0 0 1 1]\n"]},{"ename":"ValueError","evalue":"Length of values does not match length of index","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/var/folders/6d/qttwynm17cvbrhqy4k7rm57r0000gn/T/ipykernel_12709/404584807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Training and tuning Logistic Regression model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_logisticregression_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# feature_results['LogR_FeatureImportance'] = feature_results[['Feature']].merge(logr_features, how='inner',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                                 \u001b[0;31m# left_on='Feature', right_on='Parameter')['Feature Importance']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/6d/qttwynm17cvbrhqy4k7rm57r0000gn/T/ipykernel_12709/4105324370.py\u001b[0m in \u001b[0;36mmodel_logisticregression_tuned\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfeatures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Parameter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfeatures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Feature Importance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# return the features dataframe and a classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3636\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"]}],"source":["# Run the logistic regression model, extract the results\n","print('  Training and tuning Logistic Regression model...')\n","t0 = time.time()\n","logr_features, model_results['LogR'] = model_logisticregression_tuned(X_train, y_train, X_test, y_test)\n","# feature_results['LogR_FeatureImportance'] = feature_results[['Feature']].merge(logr_features, how='inner',\n","                                                                                # left_on='Feature', right_on='Parameter')['Feature Importance']\n","# t1 = time.time()\n","# print('    Done running Logistic Regression model in', str(int((t1-t0)/60)), 'mins and', str(int((t1-t0)%60)), 'secs')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["target = 'CMAD01a'"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":"166    1\n124    1\n59     0\n37     0\n88     1\n60     0\n63     0\n160    1\n51     0\n118    1\n71     0\n79     0\n2      0\n95     1\n77     0\n14     0\n154    1\n161    1\n84     1\n158    1\n94     1\n128    1\n23     0\n143    1\n80     0\n117    1\n1      0\n26     0\n92     1\n48     0\n90     1\n152    1\n91     1\n155    1\n112    1\n20     0\n72     0\n148    1\n21     0\n24     0\n57     0\n32     0\n78     0\n74     0\n29     0\n98     1\n43     0\n111    1\n116    1\n146    1\n52     0\nName: CMAD01a, dtype: int64"},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["y_test.astype(int)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["logr_features, model_results['LogR'] = model_logisticregression_tuned(X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"8a1259ec92ce41f383da58e7e41e0196"},"outputs":[],"source":["def run_models_tuned(target, df_base, df_targets):\n","    try:\n","        print('Modeling for target =', target)\n","\n","        # call the prep_and_split_data() helper function to extract the training and test sets\n","        X_train, X_test, y_train, y_test = prep_and_split_data(target, df_base, df_targets)\n","\n","        # initialize model results dictionary and feature results dataframe for selected target variable\n","        model_results = {}\n","        feature_results = initialize_feature_results(X_train)\n","\n","        # Run the logistic regression model, extract the results\n","        print('  Training and tuning Logistic Regression model...')\n","        t0 = time.time()\n","        logr_features, model_results['LogR'] = model_logisticregression_tuned(X_train, y_train, X_test, y_test)\n","        feature_results['LogR_FeatureImportance'] = feature_results[['Feature']].merge(logr_features, how='inner',\n","                                                                                       left_on='Feature', right_on='Parameter')['Feature Importance']\n","        t1 = time.time()\n","        print('    Done running Logistic Regression model in', str(int((t1-t0)/60)), 'mins and', str(int((t1-t0)%60)), 'secs')\n","\n","        # Run the random forest model, extract the results\n","        print('  Training and tuning Random Forest model...')\n","        t0 = time.time()\n","        ranf_features, model_results['RanF'] = model_randomforest_tuned(X_train, y_train, X_test, y_test)\n","        feature_results['RanF_FeatureImportance'] = feature_results[['Feature']].merge(ranf_features, how='inner',\n","                                                                                       left_on='Feature', right_on='Parameter')['Feature Importance']\n","        t1 = time.time()\n","        print('    Done running Random Forest model in', str(int((t1-t0)/60)), 'mins and', str(int((t1-t0)%60)), 'secs')\n","\n","        # Run the LGBM model, extract the results\n","        print('  Training and tuning LGBM model...')\n","        t0 = time.time()\n","        lgbm_features, model_results['LGBM'] = model_lgbm_tuned(X_train, y_train, X_test, y_test)\n","        feature_results['LGBM_FeatureImportance'] = feature_results[['Feature']].merge(lgbm_features, how='inner',\n","                                                                                       left_on='Feature', right_on='Parameter')['Feature Importance']\n","        t1 = time.time()\n","        print('    Done running LGBM model in', str(int((t1-t0)/60)), 'mins and', str(int((t1-t0)%60)), 'secs')\n","\n","        # Save results back to dictionaries\n","        model_results_dict[target]   = model_results\n","        feature_results_dict[target] = feature_results\n","        print('Modeling successful!')\n","        print()\n","        \n","    except Exception as e:\n","        print('Modeling failed, due to error')\n","        print(e)\n","        pass"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"be100a363e604b7aa9be779f0ebd5541"},"outputs":[{"name":"stdout","output_type":"stream","text":["Modeling for target = CMAD01a\n","  Dataframe shape after cleaning: (168, 2001)\n","  Training and tuning Logistic Regression model...\n","    Done running Logistic Regression model in 0 mins and 0 secs\n","  Training and tuning Random Forest model...\n"]},{"name":"stderr","output_type":"stream","text":["Process LokyProcess-43:\n","Traceback (most recent call last):\n","  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/Users/gabrielgilling/Library/Python/3.8/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 477, in _process_worker\n","    gc.collect()\n","KeyboardInterrupt\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/6d/qttwynm17cvbrhqy4k7rm57r0000gn/T/ipykernel_12709/628792247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PublicID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_models_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/var/folders/6d/qttwynm17cvbrhqy4k7rm57r0000gn/T/ipykernel_12709/2401866871.py\u001b[0m in \u001b[0;36mrun_models_tuned\u001b[0;34m(target, df_base, df_targets)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Training and tuning Random Forest model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mranf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RanF'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_randomforest_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         feature_results['RanF_FeatureImportance'] = feature_results[['Feature']].merge(ranf_features, how='inner',\n\u001b[1;32m     26\u001b[0m                                                                                        left_on='Feature', right_on='Parameter')['Feature Importance']\n","\u001b[0;32m/var/folders/6d/qttwynm17cvbrhqy4k7rm57r0000gn/T/ipykernel_12709/3075625148.py\u001b[0m in \u001b[0;36mmodel_randomforest_tuned\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# run the cross-validated grid search to identify the best parameters for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     CV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), scoring='f1',\n\u001b[0m\u001b[1;32m     14\u001b[0m                           param_grid=param_grid, n_jobs=-1, verbose=0).fit(X_train, y_train)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for target in df_targets.columns.drop('PublicID').sort_values():\n","    run_models_tuned(target, df_base, df_targets)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"f48433f4181c44f68ab398a9367c90af"},"outputs":[],"source":["with open('model_results_dict.pkl', 'wb') as f:\n","    pickle.dump(model_results_dict, f)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"0a8960b76ab5471d9f5468c78b60ff2f"},"outputs":[],"source":["with open('feature_results_dict.pkl', 'wb') as f:\n","    pickle.dump(feature_results_dict, f)"]},{"cell_type":"markdown","metadata":{"id":"8bcf17ca6714407c92fb766702d8e633"},"source":["[Back to Top](#top)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.2 64-bit","name":"python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":1}